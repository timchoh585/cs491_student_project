<!DOCTYPE html>
<html lang="en">
<head>
  <title>CS 491 - Student Choice</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
  <style>
    /* Remove the navbar's default margin-bottom and rounded borders */ 
    .navbar {
      margin-bottom: 0;
      border-radius: 0;
    }
    
    /* Set height of the grid so .sidenav can be 100% (adjust as needed) */
    .row.content {height: 450px}
    
    /* Set gray background color and 100% height */
    .sidenav {
      padding-top: 20px;
      background-color: #f1f1f1;
      height: 100%;
    }
    
    /* Set black background color, white text and some padding */
    footer {
      background-color: #555;
      color: white;
      padding: 15px;
    }
    
    /* On small screens, set height to 'auto' for sidenav and grid */
    @media screen and (max-width: 767px) {
      .sidenav {
        height: auto;
        padding: 15px;
      }
      .row.content {height:auto;} 
    }
  </style>

  <style>
    body {font-family: "Lato", sans-serif;}
    
    /* Style the tab */
    div.tab {
        overflow: hidden;
        border: 1px solid #ccc;
        background-color: #f1f1f1;
    }
    
    /* Style the buttons inside the tab */
    div.tab button {
        background-color: inherit;
        float: left;
        border: none;
        outline: none;
        cursor: pointer;
        padding: 14px 16px;
        transition: 0.3s;
        font-size: 17px;
    }
    
    /* Change background color of buttons on hover */
    div.tab button:hover {
        background-color: #ddd;
    }
    
    /* Create an active/current tablink class */
    div.tab button.active {
        background-color: #ccc;
    }
    
    /* Style the tab content */
    .tabcontent {
        display: none;
        padding: 6px 12px;
        border: 1px solid #ccc;
        border-top: none;
    }

    img {
      max-width:100%;
      height:auto;
      max-height:100%;
      margin:10px;
    }
  </style>
</head>
<body>

<nav class="navbar navbar-inverse">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#myNavbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>                        
      </button>
      <a class="navbar-brand" href="#">CS 491</a>
    </div>
  </div>
</nav>
  
<div class="container-fluid text-center">    
  <div class="row content">
    <div class="col-sm-2 sidenav">
      <p><a href="project2.html">Student Choice</a></p>
    </div>
    <div class="col-sm-8 text-left">
      <h1>CS 491 - Student Choice -- Leap Motion</h1>
      <p></p>
      <hr>
        <h3>Leap Motion</h3>
        <center>
        <p style="text-indent :5em;" >    
          Leap Motion.  What is it?  Leap motion is an advanced hand tracking technology that is used 
          in both AR and VR as shown through many examples found <a href="https://www.leapmotion.com/showcase/#111">here.</a>
            This is unique technology that has been around much longer than the Vive and Oculus have been around.  
          This is a clean way to provide hand tracking technology, within a close proximity, of the 
          device itself.
        </p>
        <p style="text-indent :5em;" >    
          Leap Motion itself is a small container with two cameras to sense depth within a given field 
          that is in its view.
        </p>
        <img src="leap_motion_controller.png">
        <p style="text-indent :5em;" >    
          Leap Motion can be used in many ways that make it easier to interect with object within 
          VR and AR.  If you back to the examples, you can see some really cool integrations of the 
          technology in AR and VR experiences.
        </p>
        <br>
        <p style="text-indent :5em;" >
          To go into further discussion about the Leap Motion, lets talk about the hardware behind it.  
          The hardware behind the tiny device is that it consists of two cameras that are used to track the 
          visible objects, the hands that are in use, as well as three infrared LEDs that are used to track 
          infrared light with a wavelength of 850nm.  With both of the two normal cameras and the three 
          infrared lights, the device, without any additional software, can track roughly two feet.  I say 
          without any additional software because Leap made new software that can extend the range of 
          around two feet to now around two and a half feet.  The change was from 60 to 80 cm if that is 
          easier to visualize.  The current distance is limited to that because of how infrared is reflected 
          off of the user's hands and the cameras, and the software, have a hard time tracking beyond that 
          distance at an accurate rate.  That is also a problem with the hardware because the LED emitters 
          are limited to pulling as much data as a USB from a laptop can provide, being that the USB needs 
          to provide power as well as for data transfer between the Leap Motion itself and the computer.  
          An improvement to this would be to update the USB A to USB C and that would provide 40 Gbps of 
          data transfer which would, in theory, allow for more power for the emitters as well as the cameras 
          that are being used to read the infrared.  But with the current hardware, the device can read 
          about two feet from the top of the device, about two feet from each side at a 150 degree angle 
          from the top of the device, and about two feet deep on each side.
        </p>
        <img src="leap_motion_interaction.png">
        <p style="text-indent :5em;" >
          Talking more about the software that was made by Leap to help extend the range of the Motion itself, 
          the software was built to enable a more natural feel with empty space.  The software has a more 
          advanced set of algorithms to read and interpret the user's hands in empty space.  The new software 
          comes with many new advancements such as: lower latency, longer range, better hand recognition to 
          track more joints in the hands, faster hand recognition for a less laggy fealing, removing cluttering 
          of what the Motion sees, removed ambient lights that conflict with the infrared and the cameras, 
          as well as better runtime for applications with an updated API.  The updated software allows for 
          a greater interaction between hands free controllers and a VR/AR system.  The software is currently 
          still in beta under the name Orion.  <a href="https://youtu.be/oZ_53T2jBGg?t=3m38s">The video will show a demo at 3:46.</a>
        </p>
        <p style="text-indent :5em;" >
          As previously mentioned, the Orion software update greatly increased the ambient occlusion within 
          tracking of the hands.  The way that the software initially worked, before the Orion update, was 
          that it uses the two cameras, which are fisheye lens to allow for the greater degree of camera 
          range, and used that to interpret the three-dimentional space that it sees.  The camera renders 
          what it sees in grayscale to be able to see the infrared and differentiate background and 
          foreground.  The Orion update allowed for a greater depth for the grayscale images that were being 
          made.  This allowed for a faster recognition of the hands as well as the addition of the tracking 
          of arms as well.  One of the many updates included an update to the cameras' distortion fix.  
          Naturally, fisheye lens cause distortion to occur in order to allow for a greater field of vision.  
          The software had been updated to allow for a better distortion fix that allowed the grayscale 
          fisheye images to look like natural grayscale images.
        </p>
        <img src="leap_motion_distortion.png">
        <p style="text-indent :5em;" >
          As mentioned, the Orion update allowed for a better infrared tracking to occur.  This allowed for 
          faster recognition as well as a more accurate recognition.
        </p>
        <img src="leap_motion_infrared.jpg">
        <p style="text-indent :5em;" >
          <a href="https://youtu.be/7HnfG0a6Gfg?t=54s">Here in the video at 54 seconds,</a> the Orion update allowed for a more natural finger prediction.  Since the 
          Leap Motion can be used in many different angles, sometimes fingers will be blocked by different 
          parts of your body.  The Orion update allowed for a better prediction to occur for fingers that 
          are directly hidden from the Leap Motion itself.  
        </p>
        <p style="text-indent :5em;" >
          <a href="https://youtu.be/7HnfG0a6Gfg?t=1m52s">Skipping forward in the video to 1:52,</a> we can see that the Orion update allowed for a better detection of 
          the hand against various backgrounds.  Since the technology is using infrared, the cameras pickup 
          what is reflected back to it from the infrared emitters on the device itself.  In the video, we 
          saw that whatever is reflected also shows a very similar color because of the grayscale, but the 
          Orion update allows for better tracking with a better use of depth from the two cameras that are 
          built into the hardware.
        </p>
        </center>
        <h3>AR/VR action</h3>
        <center>
          <p style="text-indent :5em;" >
            The Leap Motion is great for controller-less interaction for Virtual and Augmented Reality.  The Leap 
            Motion was one of many different Mixed Reality tools that were made, but the Leap Motion was advanced 
            to work with the HTC Vive and the Oculus Rift.  Leap has also made their own version of a VR headset 
            with a built-in Motion.  The Leap Motion can be used in many ways with VR headsets: the Motion can be 
            used on a table and look up to track motion that way, or be used in a way that it is attached to the 
            headset and be used like a third eye for the VR headset.
          </p>
          <img src="leap_motion_headset.png">
          <p style="text-indent :5em;" >
            The Leap Motion has a lot of different tools that <a href="https://gallery.leapmotion.com/">can be found here.</a>  
            With the Orion software that is available for the Leap Motion and the VR headsets that are out there, 
            there are a bunch of projects that utilize both to have a unique experience without controllers.  
            One of the cool tools, <a href="https://gallery.leapmotion.com/hovercast-vr-interface/">can be found here, </a>
            and this tool shows different ways that the Motion can be setup with the VR headsets that are 
            out there.
          </p>
          <img src="leap_motion_headset.png">
          <p style="text-indent :5em;" >
            The Leap Motion also has another cool tool that allows people to interact with a Virtual Machine 
            inside of a VR headset with control from the Leap Motion.  <a href="https://gallery.leapmotion.com/bigscreen-beta/">
            This project can be found here.</a>  This project is really cool because it allows you to share a 
            workspace with friends in virtual space!
          </p>
          <img src="bigscreenbeta.jpg">
        </center>
      </div>
    </div>
  </div>
</div>
<footer class="container-fluid text-center">
  <p>Timothy Choh</p>
</footer>
</body>
</html>